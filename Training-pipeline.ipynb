{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91311e2c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6a2cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649abec5",
   "metadata": {},
   "source": [
    "# Load MNIST Handwritten Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e71f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets \n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c4b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation of training data in order to make model more reliable\n",
    "\n",
    "train_augmented = T.Compose([\n",
    "    T.RandomHorizontalFlip(p = 0.5),\n",
    "    T.RandomVerticalFlip(p = 0.5),\n",
    "    T.ToTensor(), #will convert array to tensor and \n",
    "    #shift from (height, width, channel) to (channel, height, width)\n",
    "    T.Normalize(mean = 0.5, std = 0.5)\n",
    "])\n",
    "\n",
    "validation_augmented = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean = 0.5, std = 0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93bf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('./', download = False, train = True, transform = train_augmented) #we already have the dataset\n",
    "testset = datasets.MNIST('./', download = False, train = False, transform = validation_augmented) #we already have the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0622d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validationset = torch.utils.data.random_split(trainset, [50000,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36e146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of trainset : 50000\n",
      "Size of validset : 10000\n",
      "Size of testset : 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of trainset : {len(trainset)}\")\n",
    "print(f\"Size of validset : {len(validationset)}\")\n",
    "print(f\"Size of testset : {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c014f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image : torch.Size([1, 28, 28])\n",
      "For visualization we need (h x w x c) so using permute shape will be : torch.Size([28, 28, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "image, label = trainset[idx]\n",
    "\n",
    "print(f'shape of image : {image.shape}') #we will get channel, height, width, because this is a tensor\n",
    "\n",
    "print(f'For visualization we need (h x w x c) so using permute shape will be : {image.permute(1, 2, 0).shape}')\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0), cmap = 'gray')\n",
    "plt.title(label);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335aba4",
   "metadata": {},
   "source": [
    "# Load Dataset into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7c7cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6c936f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "trainloader = DataLoader(trainset, batch_size = bs, shuffle = True)\n",
    "validationloader = DataLoader(validationset, batch_size = bs)\n",
    "testloader = DataLoader(testset, batch_size = bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a48cc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of batches in trainloader : 782\n",
      "Total no. of batches in validloader : 157\n",
      "Total no. of batches in testloader : 157\n"
     ]
    }
   ],
   "source": [
    "print(f'Total no. of batches in trainloader : {len(trainloader)}')\n",
    "print(f'Total no. of batches in validloader : {len(validationloader)}')\n",
    "print(f'Total no. of batches in testloader : {len(testloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d1c00d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One image batch shape is : torch.Size([1, 28, 28])\n",
      "One labels batch shape is : torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in trainloader:\n",
    "    print(f\"One image batch shape is : {image.shape}\")\n",
    "    print(f\"One labels batch shape is : {labels.shape}\")\n",
    "    break;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca45152",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7b155bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DigitModel(\n",
       "  (cnn_block): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (linear_block): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1568, out_features=512, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import DigitModel\n",
    "model = DigitModel()\n",
    "model.to('cpu') #we will load the model in CPU, not GPU, it is good practice to define this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c3b7f",
   "metadata": {},
   "source": [
    "# Create Train and Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f2c650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training function\n",
    "def train_function(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    \n",
    "    for images, labels in tqdm(dataloader):\n",
    "        images = images.to('cpu')\n",
    "        labels = labels.to('cpu')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += utils.multiclass_accuracy(logits, labels)\n",
    "        \n",
    "    return total_loss / len(dataloader), total_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afae506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valudation function\n",
    "def validation_function(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images = images.to('cpu')\n",
    "            labels = labels.to('cpu')\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += utils.multiclass_accuracy(logits, labels)\n",
    "\n",
    "        return total_loss / len(dataloader), total_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7d43b",
   "metadata": {},
   "source": [
    "# Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9bc2b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ab29b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1c972e938549a1b502f608fec1f8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2b8791db034d1c816bcb21ae4c4874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1... Trainloss : 0.3939359156543489.... Train Accuracy: 0.8782169222831726 \n",
      "Epoch 1... Validation loss : 0.1739120866169634.... Validation Accuracy: 0.9469909071922302 \n",
      "Saved best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdbb4f538de4c60af2c0fd0857cb304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b5b0252618473394180a1ba4704ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2... Trainloss : 0.3007915490414099.... Train Accuracy: 0.9081481695175171 \n",
      "Epoch 2... Validation loss : 0.1597657617172012.... Validation Accuracy: 0.9525255560874939 \n",
      "Saved best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de9660c13684e468105004a70748771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970b94cf9b5d4c5d816a7666aa6566e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3... Trainloss : 0.2663872084006324.... Train Accuracy: 0.9197770357131958 \n",
      "Epoch 3... Validation loss : 0.13251196478476837.... Validation Accuracy: 0.9610373973846436 \n",
      "Saved best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a3dda69a7b43d7a7b4c8dfd37ad68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69a2260ba354f45b97ad83887fcb253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4... Trainloss : 0.24055271855343485.... Train Accuracy: 0.9274896383285522 \n",
      "Epoch 4... Validation loss : 0.12184560390146416.... Validation Accuracy: 0.9628956317901611 \n",
      "Saved best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fee4db523b4bdbb7ce640bf6fc9bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10baa5eb8cf84e36b8c4ef2c174ea272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5... Trainloss : 0.2222702210873861.... Train Accuracy: 0.934502899646759 \n",
      "Epoch 5... Validation loss : 0.14088074814842638.... Validation Accuracy: 0.9560222029685974 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691625ee5b144cd6b95096b979931491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05cb88b8d9f43d3a1bde1a50fde37a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6... Trainloss : 0.2123150669152627.... Train Accuracy: 0.9365409016609192 \n",
      "Epoch 6... Validation loss : 0.11167611479354293.... Validation Accuracy: 0.9663123488426208 \n",
      "Saved best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8f60b231be473f92e815f7d2d449b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e19f9cdd12e4f05ae1e65f3a9a057a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7... Trainloss : 0.20458234011021723.... Train Accuracy: 0.9394980669021606 \n",
      "Epoch 7... Validation loss : 0.11088716713330515.... Validation Accuracy: 0.9666919708251953 \n",
      "Saved best model\n"
     ]
    }
   ],
   "source": [
    "best_validation_loss = np.Inf\n",
    "\n",
    "for i in range(7): #epochs\n",
    "    train_loss, train_accuracy = train_function(model, trainloader, criterion, optimizer)\n",
    "    validation_loss, validation_accuracy = validation_function(model, trainloader, criterion)\n",
    "    print(f\"Epoch {i+1}... Trainloss : {train_loss}.... Train Accuracy: {train_accuracy} \")\n",
    "    print(f\"Epoch {i+1}... Validation loss : {validation_loss}.... Validation Accuracy: {validation_accuracy} \")\n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        torch.save(model.state_dict(), 'best_weights.pt')\n",
    "        print('Saved best model')\n",
    "        best_validation_loss = validation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfacb4ce",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "505bf818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets test our newly trained model\n",
    "image, label = testset[134]\n",
    "weights = torch.load('best_weights.pt')\n",
    "model.load_state_dict(weights)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(image.unsqueeze(0)) #image in test is channel, height, width\n",
    "    #with unsqueeze it becomes batchsize (1), channel, height, width\n",
    "    probabilities = torch.nn.Softmax(dim = 1)(logits)[0]\n",
    "    utils.view_classify(image, probabilities)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4eef3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
